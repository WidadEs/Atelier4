{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3dadfc2-1486-4073-af1a-7470ec1acb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "import ast\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb08092b-62fb-4710-90ce-42cdac374010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afea79c13e5c433a85539d479b2017a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/381 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce978b88b3fe40d598b26b6e4ea3435f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/107k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345b4d2aa99e41d1b209bc752a81995a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "data_sample = load_dataset(\"QuyenAnhDE/Diseases_Symptoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5ef780-d0c1-4b4a-959a-db78e8648846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Code', 'Name', 'Symptoms', 'Treatments'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7d7def-e40d-4c86-a123-b40ed2769186",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = [{'Name':item['Name'],'Symptoms':item['Symptoms']} for item in data_sample['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78d45e5e-5bfd-4579-a706-f2d1d7ee8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(updated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "145b3a25-b38c-40ba-b6c2-0657988bc2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panic disorder</td>\n",
       "      <td>Palpitations, Sweating, Trembling, Shortness o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vocal cord polyp</td>\n",
       "      <td>Hoarseness, Vocal Changes, Vocal Fatigue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turner syndrome</td>\n",
       "      <td>Short stature, Gonadal dysgenesis, Webbed neck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptorchidism</td>\n",
       "      <td>Absence or undescended testicle(s), empty scro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethylene glycol poisoning-1</td>\n",
       "      <td>Nausea, vomiting, abdominal pain, General mala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0               Panic disorder   \n",
       "1             Vocal cord polyp   \n",
       "2              Turner syndrome   \n",
       "3               Cryptorchidism   \n",
       "4  Ethylene glycol poisoning-1   \n",
       "\n",
       "                                            Symptoms  \n",
       "0  Palpitations, Sweating, Trembling, Shortness o...  \n",
       "1           Hoarseness, Vocal Changes, Vocal Fatigue  \n",
       "2  Short stature, Gonadal dysgenesis, Webbed neck...  \n",
       "3  Absence or undescended testicle(s), empty scro...  \n",
       "4  Nausea, vomiting, abdominal pain, General mala...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4aec60-3083-4ff7-85c3-722b46e215d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the symptopms\n",
    "\n",
    "df['Symptoms'] = df['Symptoms'].apply(lambda x:', '.join(x.split(', ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a7b408-7c18-434a-81bc-8bb34347be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656df849-e3c1-411f-afd6-697bd79fd6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "\n",
    "else:\n",
    "  try:\n",
    "    device = torch.device('mps')\n",
    "  except Exception:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ea6dbb-ce54-4c0e-b971-9ac3e094a495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4af3a59-24fb-4a83-9167-1c8225c39ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.3.0-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchvision-0.18.0-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.2 MB 640.0 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.2 MB 762.6 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.4/1.2 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.8/1.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.3.0-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.6/2.4 MB 17.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 8.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.4 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 7.5 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-2.3.0 torchvision-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9990ce36-17a7-48db-871c-a1a07f97b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f6acaa-bb27-4adf-9264-1d58386fe8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72ec4e68-106a-46bf-9278-da2b9ee91859",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "086aff3b-1853-49a5-8e07-dbd99aea4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "\n",
    "class LanguageDataset(Dataset):\n",
    "  def __init__(self,df, tokenizer):\n",
    "    self.labels = df.columns\n",
    "    self.data = df.to_dict(orient = 'records')\n",
    "    self.tokenizer = tokenizer\n",
    "    x = self.fittest_max_length(df)\n",
    "    self.max_length = x\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    x = self.data[idx][self.labels[0]]\n",
    "    y = self.data[idx][self.labels[1]]\n",
    "    text = f\"{x} | {y}\"\n",
    "    tokens = self.tokenizer.encode_plus(text, return_tensors = 'pt', max_length=128, padding = 'max_length', truncation=True)\n",
    "    return tokens\n",
    "\n",
    "  def fittest_max_length(self, df):\n",
    "    \"\"\"\n",
    "    Smallest power of two larger than the longest term in the data set.\n",
    "    Important to set up max length to speed training time.\n",
    "    \"\"\"\n",
    "    max_length = max(len(max(df[self.labels[0]], key=len)), len(max(df[self.labels[1]], key=len)))\n",
    "    x = 2\n",
    "    while x < max_length: x = x * 2\n",
    "    return x\n",
    "\n",
    "# Cast the Huggingface data set as a LanguageDataset we defined above\n",
    "data_sample = LanguageDataset(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80f30c72-bfb7-48cf-8136-3f3a63f91f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LanguageDataset at 0x26383bf9610>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acdb4275-740a-4a76-b7aa-2f6707617339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, valid\n",
    "train_size = int(0.8 * len(data_sample))\n",
    "valid_size = len(data_sample) - train_size\n",
    "train_data, valid_data = random_split(data_sample, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55b0d682-4604-423b-9ace-dedf6a5d094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the iterators\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a0259f5-6d10-4f93-9c88-e4686ed6fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5042b9ac-669d-47a8-bf0a-96668a987a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = BATCH_SIZE\n",
    "model_name = 'distilgpt2'\n",
    "gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3e9d2f0-6cda-4ad9-94e0-2d46c8617910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate and loss function\n",
    "## CrossEntropyLoss measures how close answers to the truth.\n",
    "## More punishing for high confidence wrong answers\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f348e1c2-fd3e-4a38-a302-726d75b435a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init a results dataframe\n",
    "results = pd.DataFrame(columns=['epoch', 'transformer', 'batch_size', 'gpu',\n",
    "                                'training_loss', 'validation_loss', 'epoch_duration_sec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffb0cc57-6466-4618-b88e-1e5f9c1e3527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [04:07<00:00,  6.20s/it, Training Loss=0.698]\n",
      "Validation Epoch 1/10: 100%|█████████████████████████████████████| 10/10 [00:22<00:00,  2.26s/it, Validation Loss=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Validation Loss: 0.7025867700576782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [04:21<00:00,  6.55s/it, Training Loss=0.643]\n",
      "Validation Epoch 2/10: 100%|████████████████████████████████████| 10/10 [00:22<00:00,  2.25s/it, Validation Loss=0.592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Validation Loss: 0.6828542351722717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [04:15<00:00,  6.38s/it, Training Loss=0.358]\n",
      "Validation Epoch 3/10: 100%|████████████████████████████████████| 10/10 [00:22<00:00,  2.30s/it, Validation Loss=0.596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Validation Loss: 0.7073461413383484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [04:15<00:00,  6.38s/it, Training Loss=0.312]\n",
      "Validation Epoch 4/10: 100%|████████████████████████████████████| 10/10 [00:22<00:00,  2.25s/it, Validation Loss=0.627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Validation Loss: 0.7235472202301025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [04:15<00:00,  6.39s/it, Training Loss=0.244]\n",
      "Validation Epoch 5/10: 100%|████████████████████████████████████| 10/10 [00:22<00:00,  2.25s/it, Validation Loss=0.646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Validation Loss: 0.791861891746521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [04:41<00:00,  7.03s/it, Training Loss=0.208]\n",
      "Validation Epoch 6/10: 100%|█████████████████████████████████████| 10/10 [00:36<00:00,  3.64s/it, Validation Loss=0.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Validation Loss: 0.8438986539840698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [06:49<00:00, 10.25s/it, Training Loss=0.197]\n",
      "Validation Epoch 7/10: 100%|████████████████████████████████████| 10/10 [00:36<00:00,  3.67s/it, Validation Loss=0.731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Validation Loss: 0.9023510217666626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [06:52<00:00, 10.32s/it, Training Loss=0.0873\n",
      "Validation Epoch 8/10: 100%|████████████████████████████████████| 10/10 [00:36<00:00,  3.66s/it, Validation Loss=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Validation Loss: 0.8971129655838013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [06:53<00:00, 10.33s/it, Training Loss=0.0916\n",
      "Validation Epoch 9/10: 100%|████████████████████████████████████| 10/10 [00:36<00:00,  3.66s/it, Validation Loss=0.783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Validation Loss: 0.9510866403579712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10 Batch Size: 8, Transformer: distilgpt2: 100%|█| 40/40 [06:53<00:00, 10.34s/it, Training Loss=0.085\n",
      "Validation Epoch 10/10: 100%|███████████████████████████████████| 10/10 [00:36<00:00,  3.67s/it, Validation Loss=0.835]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Validation Loss: 0.9878532290458679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start the timer for the epoch\n",
    "\n",
    "    # Training\n",
    "    ## This line tells the model we're in 'learning mode'\n",
    "    model.train()\n",
    "    epoch_training_loss = 0\n",
    "    train_iterator = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs} Batch Size: {batch_size}, Transformer: {model_name}\")\n",
    "    for batch in train_iterator:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "        targets = inputs.clone()\n",
    "        outputs = model(input_ids=inputs, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iterator.set_postfix({'Training Loss': loss.item()})\n",
    "        epoch_training_loss += loss.item()\n",
    "    avg_epoch_training_loss = epoch_training_loss / len(train_iterator)\n",
    "\n",
    "    # Validation\n",
    "    ## This line below tells the model to 'stop learning'\n",
    "    model.eval()\n",
    "    epoch_validation_loss = 0\n",
    "    total_loss = 0\n",
    "    valid_iterator = tqdm(valid_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_iterator:\n",
    "            inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "            targets = inputs.clone()\n",
    "            outputs = model(input_ids=inputs, labels=targets)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss\n",
    "            valid_iterator.set_postfix({'Validation Loss': loss.item()})\n",
    "            epoch_validation_loss += loss.item()\n",
    "\n",
    "    avg_epoch_validation_loss = epoch_validation_loss / len(valid_loader)\n",
    "\n",
    "    end_time = time.time()  # End the timer for the epoch\n",
    "    epoch_duration_sec = end_time - start_time  # Calculate the duration in seconds\n",
    "\n",
    "    new_row = {'transformer': model_name,\n",
    "               'batch_size': batch_size,\n",
    "               'gpu': gpu,\n",
    "               'epoch': epoch+1,\n",
    "               'training_loss': avg_epoch_training_loss,\n",
    "               'validation_loss': avg_epoch_validation_loss,\n",
    "               'epoch_duration_sec': epoch_duration_sec}  # Add epoch_duration to the dataframe\n",
    "\n",
    "    results.loc[len(results)] = new_row\n",
    "    print(f\"Epoch: {epoch+1}, Validation Loss: {total_loss/len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba704617-c3b6-4197-b913-e14dab313add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kidney Failure | Severe abdominal or back pain, blood in urine, frequent urination\n"
     ]
    }
   ],
   "source": [
    "input_str = \"Kidney Failure\"\n",
    "input_ids = tokenizer.encode(input_str, return_tensors='pt').to(device)\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=20,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    top_k=8,\n",
    "    top_p=0.95,\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
