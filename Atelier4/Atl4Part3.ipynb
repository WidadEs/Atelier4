{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import json\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:01:17.394184Z",
     "iopub.status.busy": "2024-05-26T14:01:17.393341Z",
     "iopub.status.idle": "2024-05-26T14:01:17.422237Z",
     "shell.execute_reply": "2024-05-26T14:01:17.421367Z",
     "shell.execute_reply.started": "2024-05-26T14:01:17.394149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:02:40.091718Z",
     "iopub.status.busy": "2024-05-26T14:02:40.090878Z",
     "iopub.status.idle": "2024-05-26T14:02:40.168964Z",
     "shell.execute_reply": "2024-05-26T14:02:40.168124Z",
     "shell.execute_reply.started": "2024-05-26T14:02:40.091684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   overall  verified  reviewTime     reviewerID        asin  \\\n",
      "0      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
      "1      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
      "2      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
      "3      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
      "4      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
      "\n",
      "                                               style reviewerName  \\\n",
      "0   {'Size:': ' Big Boys', 'Color:': ' Blue/Orange'}     Tonya B.   \n",
      "1  {'Size:': ' Big Boys', 'Color:': ' Black (3746...     Tonya B.   \n",
      "2  {'Size:': ' Big Boys', 'Color:': ' Blue/Gray L...     Tonya B.   \n",
      "3  {'Size:': ' Big Boys', 'Color:': ' Blue (37867...     Tonya B.   \n",
      "4     {'Size:': ' Big Boys', 'Color:': ' Blue/Pink'}     Tonya B.   \n",
      "\n",
      "                 reviewText     summary  unixReviewTime vote image  \n",
      "0  Great product and price!  Five Stars      1441324800  NaN   NaN  \n",
      "1  Great product and price!  Five Stars      1441324800  NaN   NaN  \n",
      "2  Great product and price!  Five Stars      1441324800  NaN   NaN  \n",
      "3  Great product and price!  Five Stars      1441324800  NaN   NaN  \n",
      "4  Great product and price!  Five Stars      1441324800  NaN   NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Chemin vers le fichier JSON\n",
    "chemin_fichier = '/kaggle/input/amazon-fashion-51/AMAZON_FASHION_5.json'\n",
    "\n",
    "# Liste pour stocker les données JSON individuelles\n",
    "donnees_json = []\n",
    "\n",
    "# Lecture du fichier JSON ligne par ligne\n",
    "with open(chemin_fichier, 'r') as fichier:\n",
    "    for ligne in fichier:\n",
    "        donnees_json.append(json.loads(ligne))\n",
    "\n",
    "# Création d'un DataFrame à partir des données JSON\n",
    "df = pd.DataFrame(donnees_json)\n",
    "\n",
    "# Filtrer les lignes où \"reviewText\" est une chaîne de caractères\n",
    "df = df[df[\"reviewText\"].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:02:51.562910Z",
     "iopub.status.busy": "2024-05-26T14:02:51.562540Z",
     "iopub.status.idle": "2024-05-26T14:02:51.568076Z",
     "shell.execute_reply": "2024-05-26T14:02:51.567004Z",
     "shell.execute_reply.started": "2024-05-26T14:02:51.562880Z"
    }
   },
   "outputs": [],
   "source": [
    "input_texts = df[\"reviewText\"].tolist()\n",
    "labels = df[\"overall\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:03:20.889029Z",
     "iopub.status.busy": "2024-05-26T14:03:20.888665Z",
     "iopub.status.idle": "2024-05-26T14:03:25.625942Z",
     "shell.execute_reply": "2024-05-26T14:03:25.625149Z",
     "shell.execute_reply.started": "2024-05-26T14:03:20.888999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc033459b4840599d2f7ca1a27d7009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47a23f89c8044e486905c8f3142ecd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00f125657f5455f9a3f4af08e584dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5d6e132e864633919c0220a2374983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "encoded_inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:03:47.018936Z",
     "iopub.status.busy": "2024-05-26T14:03:47.018317Z",
     "iopub.status.idle": "2024-05-26T14:03:47.037827Z",
     "shell.execute_reply": "2024-05-26T14:03:47.036990Z",
     "shell.execute_reply.started": "2024-05-26T14:03:47.018895Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/3652536891.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "dataset = TensorDataset(encoded_inputs['input_ids'], encoded_inputs['attention_mask'], labels)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "eval_size = len(dataset) - train_size\n",
    "train_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:04:15.925155Z",
     "iopub.status.busy": "2024-05-26T14:04:15.924788Z",
     "iopub.status.idle": "2024-05-26T14:04:15.929890Z",
     "shell.execute_reply": "2024-05-26T14:04:15.928975Z",
     "shell.execute_reply.started": "2024-05-26T14:04:15.925124Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:04:39.404396Z",
     "iopub.status.busy": "2024-05-26T14:04:39.403190Z",
     "iopub.status.idle": "2024-05-26T14:04:42.088291Z",
     "shell.execute_reply": "2024-05-26T14:04:42.087267Z",
     "shell.execute_reply.started": "2024-05-26T14:04:39.404336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecc1ea1a602443cb6417b32768910b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1).to(device)\n",
    "optimizer = torch.optim.AdamW(bert_model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:05:04.036989Z",
     "iopub.status.busy": "2024-05-26T14:05:04.036228Z",
     "iopub.status.idle": "2024-05-26T14:09:48.965667Z",
     "shell.execute_reply": "2024-05-26T14:09:48.964655Z",
     "shell.execute_reply.started": "2024-05-26T14:05:04.036933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Training Loss: 1.1442, Evaluation Loss: 0.1197\n",
      "Epoch [2/3], Training Loss: 0.0801, Evaluation Loss: 0.0524\n",
      "Epoch [3/3], Training Loss: 0.0507, Evaluation Loss: 0.0459\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    bert_model.train()\n",
    "    total_train_loss = 0.0\n",
    "    num_train_batches = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, label = [t.to(device) for t in batch]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask, labels=label)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "\n",
    "    # Evaluation\n",
    "    bert_model.eval()\n",
    "    total_eval_loss = 0.0\n",
    "    num_eval_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            input_ids, attention_mask, label = [t.to(device) for t in batch]\n",
    "            outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask, labels=label)\n",
    "            total_eval_loss += outputs.loss.item()\n",
    "            num_eval_batches += 1\n",
    "    avg_eval_loss = total_eval_loss / num_eval_batches\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Evaluation Loss: {avg_eval_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:10:13.529540Z",
     "iopub.status.busy": "2024-05-26T14:10:13.528866Z",
     "iopub.status.idle": "2024-05-26T14:10:13.552439Z",
     "shell.execute_reply": "2024-05-26T14:10:13.551505Z",
     "shell.execute_reply.started": "2024-05-26T14:10:13.529502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating: 2.91\n"
     ]
    }
   ],
   "source": [
    "review_text = \"I dont like it\"\n",
    "\n",
    "tokenized_review = tokenizer(review_text, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "input_ids = tokenized_review['input_ids'].to(device)\n",
    "attention_mask = tokenized_review['attention_mask'].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    bert_model.eval()\n",
    "    outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    predicted_rating = outputs.logits.item()\n",
    "\n",
    "print(f\"Predicted rating: {predicted_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A rating of 2.91 could suggest a slightly negative sentiment or a neutral sentiment leaning towards negativity, depending on the scale or context of the rating system. It's important to note that the interpretation of the predicted rating may vary based on the specific dataset, task, and criteria used for sentiment analysis or regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T14:11:44.668726Z",
     "iopub.status.busy": "2024-05-26T14:11:44.668336Z",
     "iopub.status.idle": "2024-05-26T14:11:44.688649Z",
     "shell.execute_reply": "2024-05-26T14:11:44.687709Z",
     "shell.execute_reply.started": "2024-05-26T14:11:44.668695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating: 4.47\n"
     ]
    }
   ],
   "source": [
    "review_text = \"This is nice\"\n",
    "\n",
    "tokenized_review = tokenizer(review_text, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "input_ids = tokenized_review['input_ids'].to(device)\n",
    "attention_mask = tokenized_review['attention_mask'].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    bert_model.eval()\n",
    "    outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    predicted_rating = outputs.logits.item()\n",
    "\n",
    "print(f\"Predicted rating: {predicted_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AA rating of 4.47 on an assumed scale suggests a highly positive sentiment, indicating that the input text is perceived as favorable or enjoyable by the model. However, it's important to consider the specific rating scale and context of the sentiment analysis task to interpret the predicted rating accurately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5088826,
     "sourceId": 8522448,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
